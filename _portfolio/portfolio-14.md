---
title: "Generative adversarial Model"
collection: talks
type: "Tutorial"
permalink: /portfolio/portfolio-14
---

<span style="color:rgba(82,173,200,255)"> **Keys words** </span>:\
*Generative Model (VAE), Adversarial black/white box attack, probabilistic graphical models* \
<span style="color:rgba(82,173,200,255)">**Objective**</span> \\
*The article "[Are Generative Classifiers More Robust to Adversarial Attacks?](https://arxiv.org/pdf/1802.06552)" investigates the robustness of deep neural network classifiers against adversarial attacks. The focus is on the comparison between generative classifiers, which model the conditional distribution of labels given inputs, and discriminative classifiers. The authors propose the deep Bayes classifier, which is an improvement over the classical naive Bayes, using conditional deep generative models. We re-implemented the 7 different models from scratch for the MNIST, FashionMNIST and SVHN datasets. We then implemented a white box attack $l_{\infty}$ and a black box attack zoo. We then tested the generative models versus the discriminative models.*\
<img src='/images/pgm/generative models.png' width='500' height='333'><img src='/images/pgm/poster.png' width='400' height='266'> \
<span style="color:rgba(82,173,200,255)"> **Links** </span> \
[<img src="/images/GitHub.png" alt="GitHub" width="37.5" height="12.5" />](https://github.com/b-ptiste/generative-model-adv-attack) [<img src="/images/report_icone.png" alt="Report" width="37.5" height="12.5" />](https://drive.google.com/file/d/1Uid8mWEvAFNFBUSGKxk1dxgSghFufcPz/view?usp=drive_link) [<img src="/images/report_icone.png" alt="Report" width="37.5" height="12.5" />](https://drive.google.com/file/d/1elRmy-GWLtpTIibrHbGMleaMZp5Yq6B4/view?usp=drive_link) [<img src="/images/class_icone.png" alt="Report" width="37.5" height="12.5" />](https://www.master-mva.com/cours/probabilistic-graphical-models/)

